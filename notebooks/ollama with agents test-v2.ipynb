{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "414d5547-2eae-47fd-afb7-b8aa125ae445",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, Runner, SQLiteSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "262b50a9-2242-4227-8993-27364e366141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2315f9f8-66fe-43f1-9b52-34bdd2a44c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AsyncOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbbe56ed-f23b-455b-926a-299ea008fb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, OpenAIChatCompletionsModel, Runner, function_tool, set_tracing_disabled\n",
    "base_url = 'http://localhost:11434/v1'\n",
    "api_key = 'ollama'\n",
    "client  = AsyncOpenAI(base_url=base_url,api_key=api_key )\n",
    "set_tracing_disabled(disabled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cebe80ae-4ded-4938-b021-fd85aebbc96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from pathlib import Path\n",
    "current_dir = Path.cwd()\n",
    "project_root = current_dir.parent\n",
    "mlflow_logs = project_root / \"mlflow_logs\"\n",
    "mlflow_logs.mkdir(exist_ok=True)\n",
    "db_path = mlflow_logs / \"mlflow.db\"\n",
    "\n",
    "mlflow.set_tracking_uri(f\"sqlite:///{db_path.resolve()}\")\n",
    "mlflow.openai.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04eb8f91-2ce0-45cb-891d-38544c8bb9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def get_weather(city: str):\n",
    "    print(f\"[debug] getting weather for {city}\")\n",
    "    return f\"The weather in {city} is sunny.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebd84489-335c-4b9d-a4c5-f42ae10c8c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'qwen3:14b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d70765c1-a173-4083-9b50-3d9cf6f2c3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main(prompt):\n",
    "    # This agent will use the custom LLM provider\n",
    "    agent = Agent(\n",
    "        name=\"Assistant\",\n",
    "        instructions=\"You are a helpful assistant.\",\n",
    "        model=OpenAIChatCompletionsModel(model=MODEL_NAME, openai_client=client),\n",
    "        tools=[get_weather],\n",
    "    )\n",
    "\n",
    "    result = await Runner.run(agent, prompt)\n",
    "    print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54b08efa-b535-4936-b230-dc51338f4f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/04 19:23:43 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2025/12/04 19:23:43 INFO mlflow.store.db.utils: Updating database tables\n",
      "2025-12-04 19:23:43 INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "2025-12-04 19:23:43 INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "2025-12-04 19:23:43 INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "2025-12-04 19:23:43 INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[debug] getting weather for Tokyo\n",
      "The weather in Tokyo is sunny. ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What's the weather in Tokyo?\"\n",
    "await main(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "113dba05-8567-46a9-a699-35465b4dc24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pros and cons of generative AI can be summarized as follows:\n",
      "\n",
      "### **Pros**:\n",
      "1. **Creativity & Efficiency**: Generates unique content (text, images, code) quickly, aiding in tasks like writing, design, and problem-solving.\n",
      "2. **Scalability**: Automates repetitive tasks, reducing time and cost for businesses (e.g., customer support, marketing).\n",
      "3. **Personalization**: Creates tailored content for users (e.g., personalized recommendations, adaptive learning materials).\n",
      "4. **Innovation**: Explores novel ideas, aiding research, art, and scientific simulations.\n",
      "\n",
      "### **Cons**:\n",
      "1. **Accuracy & Reliability**: May produce hallucinations or incorrect information, requiring human verification.\n",
      "2. **Ethical Risks**: Potential for misuse (e.g., deepfakes, misinformation, plagiarism).\n",
      "3. **Bias**: Reflects biases in training data, leading to unfair or discriminatory outputs.\n",
      "4. **Job Displacement**: Could disrupt industries reliant on routine tasks (e.g., writing, design).\n",
      "\n",
      "Would you like further details on any specific aspect?\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What are pros and cons of Generative AI ?\"\n",
    "await main(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b60d063-f31d-4518-88c9-a74a0a5c0422",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
