{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b93d2659-2eec-44d5-91ca-4a955d976ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## From https://cookbook.openai.com/examples/orchestrating_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c3907f1-376d-4bfe-9fb8-24e76d95e184",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from openai import OpenAI, AsyncOpenAI\n",
    "from pydantic import BaseModel\n",
    "from typing import Optional\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d0af4c0-3ae0-4e21-bc8f-73795697914c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, OpenAIChatCompletionsModel, Runner, function_tool, set_tracing_disabled\n",
    "base_url = 'http://localhost:11434/v1'\n",
    "api_key = 'ollama'\n",
    "client  = OpenAI(base_url=base_url,api_key=api_key )\n",
    "#set_tracing_disabled(disabled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c09d6ce-d36e-4616-8bc8-3738cd344ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/05 09:57:10 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2025/12/05 09:57:11 INFO mlflow.store.db.utils: Updating database tables\n",
      "2025-12-05 09:57:11 INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "2025-12-05 09:57:11 INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "2025-12-05 09:57:11 INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "2025-12-05 09:57:11 INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from pathlib import Path\n",
    "current_dir = Path.cwd()\n",
    "project_root = current_dir.parent\n",
    "mlflow_logs = project_root / \"mlflow_logs\"\n",
    "mlflow_logs.mkdir(exist_ok=True)\n",
    "db_path = mlflow_logs / \"mlflow.db\"\n",
    "\n",
    "mlflow.set_tracking_uri(f\"sqlite:///{db_path.resolve()}\")\n",
    "mlflow.set_experiment(\"openai demo from website\")\n",
    "mlflow.openai.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1666afd2-0abe-442b-b94c-1b0817951004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer Service Routine\n",
    "\n",
    "system_message = (\n",
    "    \"You are a customer support agent for ACME Inc.\"\n",
    "    \"Always answer in a sentence or less.\"\n",
    "    \"Follow the following routine with the user:\"\n",
    "    \"1. First, ask probing questions and understand the user's problem deeper.\\n\"\n",
    "    \" - unless the user has already provided a reason.\\n\"\n",
    "    \"2. Propose a fix (make one up).\\n\"\n",
    "    \"3. ONLY if not satisfied, offer a refund.\\n\"\n",
    "    \"4. If accepted, search for the ID and then execute refund.\"\n",
    "    \"\"\n",
    ")\n",
    "\n",
    "#@function_tool\n",
    "def look_up_item(search_query):\n",
    "    \"\"\"Use to find item ID.\n",
    "    Search query can be a description or keywords.\"\"\"\n",
    "\n",
    "    # return hard-coded item ID - in reality would be a lookup\n",
    "    return \"item_132612938\"\n",
    "\n",
    "#@function_tool\n",
    "def execute_refund(item_id, reason=\"not provided\"):\n",
    "\n",
    "    print(\"Summary:\", item_id, reason) # lazy summary\n",
    "    return \"success\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8f2406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer Service Routine\n",
    "\n",
    "system_message = (\n",
    "    \"You are a customer support agent for ACME Inc.\"\n",
    "    \"Always answer in a sentence or less.\"\n",
    "    \"Follow the following routine with the user:\"\n",
    "    \"1. First, ask probing questions and understand the user's problem deeper.\\n\"\n",
    "    \" - unless the user has already provided a reason.\\n\"\n",
    "    \"2. Propose a fix (make one up).\\n\"\n",
    "    \"3. ONLY if not satisfied, offer a refund.\\n\"\n",
    "    \"4. If accepted, search for the ID and then execute refund.\"\n",
    "    \"\"\n",
    ")\n",
    "\n",
    "#@function_tool\n",
    "def look_up_item(search_query):\n",
    "    \"\"\"Use to find item ID.\n",
    "    Search query can be a description or keywords.\"\"\"\n",
    "\n",
    "    # return hard-coded item ID - in reality would be a lookup\n",
    "    return \"item_132612938\"\n",
    "\n",
    "#@function_tool\n",
    "def execute_refund(item_id, reason=\"not provided\"):\n",
    "\n",
    "    print(\"Summary:\", item_id, reason) # lazy summary\n",
    "    return \"success\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "735286a8-5371-4d7a-b23b-e56215a8ec68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "def function_to_schema(func) -> dict:\n",
    "    type_map = {\n",
    "        str: \"string\",\n",
    "        int: \"integer\",\n",
    "        float: \"number\",\n",
    "        bool: \"boolean\",\n",
    "        list: \"array\",\n",
    "        dict: \"object\",\n",
    "        type(None): \"null\",\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        signature = inspect.signature(func)\n",
    "    except ValueError as e:\n",
    "        raise ValueError(\n",
    "            f\"Failed to get signature for function {func.__name__}: {str(e)}\"\n",
    "        )\n",
    "\n",
    "    parameters = {}\n",
    "    for param in signature.parameters.values():\n",
    "        try:\n",
    "            param_type = type_map.get(param.annotation, \"string\")\n",
    "        except KeyError as e:\n",
    "            raise KeyError(\n",
    "                f\"Unknown type annotation {param.annotation} for parameter {param.name}: {str(e)}\"\n",
    "            )\n",
    "        parameters[param.name] = {\"type\": param_type}\n",
    "\n",
    "    required = [\n",
    "        param.name\n",
    "        for param in signature.parameters.values()\n",
    "        if param.default == inspect._empty\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": func.__name__,\n",
    "            \"description\": (func.__doc__ or \"\").strip(),\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": parameters,\n",
    "                \"required\": required,\n",
    "            },\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "raw",
   "id": "438199c9-3e3c-48b5-a24f-0e412b65c60e",
   "metadata": {},
   "source": [
    "def run_full_turn(system_message, messages):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"qwen3:14b\",\n",
    "        messages=[{\"role\": \"system\", \"content\": system_message}] + messages,\n",
    "        tools = tools\n",
    "    )\n",
    "    message = response.choices[0].message\n",
    "    messages.append(message)\n",
    "\n",
    "    if message.content: print(\"Assistant:\", message.content)\n",
    "    return message\n",
    "\n",
    "\n",
    "messages = []\n",
    "while True:\n",
    "    user = input(\"User: \")\n",
    "    messages.append({\"role\": \"user\", \"content\": user})\n",
    "\n",
    "    run_full_turn(system_message, messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bc21fe4-f4d4-48c1-9baf-4ccd294c980c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'qwen3:14b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a861fd02-d108-4817-825e-57cd0666f2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "#tools = [execute_refund, look_up_item]\n",
    "#tool_schemas = [function_to_schema(tool) for tool in tools]\n",
    "#tools = [execute_refund.params_json_schema, look_up_item.params_json_schema]\n",
    "tools = [execute_refund, look_up_item]\n",
    "tool_schemas = [function_to_schema(tool) for tool in tools]\n",
    "response = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[{\"role\": \"user\", \"content\": \"Look up the black boot.\"}],\n",
    "            tools=tool_schemas,\n",
    "        )\n",
    "message = response.choices[0].message\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9dfe932-ff68-47f8-b976-a3d4a1a888e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content='', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[ChatCompletionMessageFunctionToolCall(id='call_q7ngvm6q', function=Function(arguments='{\"search_query\":\"black boot\"}', name='look_up_item'), type='function', index=0)], reasoning='Okay, the user wants to look up the black boot. Let me check the available tools. There\\'s the look_up_item function which requires a search_query. The user mentioned \"black boot,\" so I should use that as the search query. I need to make sure the parameters are correctly formatted. The function doesn\\'t require any other parameters, just the search query. So I\\'ll generate the tool call with \"black boot\" as the search_query.\\n')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d812b90-23e4-4678-bc3d-243fa432b3f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatCompletionMessageFunctionToolCall(id='call_q7ngvm6q', function=Function(arguments='{\"search_query\":\"black boot\"}', name='look_up_item'), type='function', index=0)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37463acd-c2e5-44c3-81c9-6009c564c0ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Function(arguments='{\"search_query\":\"black boot\"}', name='look_up_item')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message.tool_calls[0].function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66755283-0d20-4b3d-a166-af8c2724b47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: look_up_item({'search_query': 'black boot'})\n"
     ]
    }
   ],
   "source": [
    "tools_map = {tool.__name__: tool for tool in tools}\n",
    "\n",
    "def execute_tool_call(tool_call, tools_map):\n",
    "    name = tool_call.function.name\n",
    "    args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "    print(f\"Assistant: {name}({args})\")\n",
    "\n",
    "    # call corresponding function with provided arguments\n",
    "    return tools_map[name](**args)\n",
    "\n",
    "for tool_call in message.tool_calls:\n",
    "            result = execute_tool_call(tool_call, tools_map)\n",
    "\n",
    "            # add result back to conversation \n",
    "            result_message = {\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"content\": result,\n",
    "            }\n",
    "            messages.append(result_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879754c2-243e-48c1-81f7-553bc62c52d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb83c7ad-2e7c-4f48-8225-559467492696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf2976b-2829-4a82-bde7-afed5c0f28c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
