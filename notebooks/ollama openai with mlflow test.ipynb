{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9e2be3d-1d98-4081-8761-cd01ea54aa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "from openai import OpenAI\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "# Silence migration logs\n",
    "logging.getLogger(\"mlflow\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"alembic\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"sqlalchemy\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af770d9e-a4a2-444d-b029-85b6f6078d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.openai.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58bb7b84-d130-443d-a16f-cbd6b1ddc33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'http://localhost:11434/api/generate'\n",
    "api_key = 'ollama'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ae904a0-4c55-483d-8972-dea9621daca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(base_url = base_url, api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ece304b8-7f60-4d42-9ef1-71f0a971b6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "current_dir = Path.cwd()\n",
    "project_root = current_dir.parent\n",
    "mlflow_logs = project_root / \"mlflow_logs\"\n",
    "mlflow_logs.mkdir(exist_ok=True)\n",
    "db_path = mlflow_logs / \"mlflow.db\"\n",
    "\n",
    "mlflow.set_tracking_uri(f\"sqlite:///{db_path.resolve()}\")\n",
    "mlflow.openai.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53bf9e51-dc6a-4f2f-a910-181a057faa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'qwen3:14b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b01467e5-51f3-4103-9e7d-3f3673e5c8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "\n",
    "    # required but ignored\n",
    "    api_key='ollama',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff2bb4d4-bf09-4bb2-9d07-df020bd76ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 18:49:42 INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "2025-12-03 18:49:42 INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "2025-12-03 18:49:42 INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "2025-12-03 18:49:42 INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n"
     ]
    }
   ],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': 'Say this is a test',\n",
    "        }\n",
    "    ],\n",
    "    model=model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "516b4056-317d-4275-8e97-f91a61a1de55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-784',\n",
       " 'choices': [{'finish_reason': 'stop',\n",
       "   'index': 0,\n",
       "   'logprobs': None,\n",
       "   'message': {'content': 'Sure! This is a test. How can I assist you today?',\n",
       "    'refusal': None,\n",
       "    'role': 'assistant',\n",
       "    'annotations': None,\n",
       "    'audio': None,\n",
       "    'function_call': None,\n",
       "    'tool_calls': None,\n",
       "    'reasoning': 'Okay, the user said \"Say this is a test.\" I need to figure out how to respond. Let me start by understanding the context. Maybe they want to check if I\\'m functioning properly or if there\\'s a specific test they\\'re referring to. Since they mentioned it\\'s a test, I should acknowledge that and ask for more details. They might be testing my ability to follow instructions or my response to certain prompts.\\n\\nI should keep the response friendly and open-ended. Let them know I\\'m here to help and ask how I can assist them. Maybe they have a particular task in mind. I need to make sure my reply is polite and encourages them to provide more information. Also, I should check if there\\'s any hidden meaning or specific requirement in their message that I might have missed. Let me phrase it in a way that\\'s inviting and helpful.\\n'}}],\n",
       " 'created': 1764767989,\n",
       " 'model': 'qwen3:14b',\n",
       " 'object': 'chat.completion',\n",
       " 'service_tier': None,\n",
       " 'system_fingerprint': 'fp_ollama',\n",
       " 'usage': {'completion_tokens': 192,\n",
       "  'prompt_tokens': 15,\n",
       "  'total_tokens': 207,\n",
       "  'completion_tokens_details': None,\n",
       "  'prompt_tokens_details': None}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_completion.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df12275c-7160-4f0d-b713-07590a76a91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_completion = client.models.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "097f6a81-6f9f-4fd2-8642-468076b46c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [{'id': 'qwen3:14b',\n",
       "   'created': 1764683523,\n",
       "   'object': 'model',\n",
       "   'owned_by': 'library'},\n",
       "  {'id': 'gemma3:12b',\n",
       "   'created': 1764681531,\n",
       "   'object': 'model',\n",
       "   'owned_by': 'library'},\n",
       "  {'id': 'qwen3-vl:8b',\n",
       "   'created': 1764675308,\n",
       "   'object': 'model',\n",
       "   'owned_by': 'library'}],\n",
       " 'object': 'list'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_completion.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5929a3f-fa97-408a-a3d5-35686a8e4e54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26fd35fb-cb41-4d45-9c8d-2b88244504d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "friends=[FriendInfo(name='Ollama', age=22, is_available=False), FriendInfo(name='Alonso', age=23, is_available=True)]\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")\n",
    "\n",
    "# Define the schema for the response\n",
    "class FriendInfo(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    is_available: bool\n",
    "\n",
    "class FriendList(BaseModel):\n",
    "    friends: list[FriendInfo]\n",
    "\n",
    "try:\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        temperature=0,\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"I have two friends. The first is Ollama 22 years old busy saving the world, and the second is Alonso 23 years old and wants to hang out. Return a list of friends in JSON format\"}\n",
    "        ],\n",
    "        response_format=FriendList,\n",
    "    )\n",
    "\n",
    "    friends_response = completion.choices[0].message\n",
    "    if friends_response.parsed:\n",
    "        print(friends_response.parsed)\n",
    "    elif friends_response.refusal:\n",
    "        print(friends_response.refusal)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43cd47d9-1ed8-455f-b0a4-6b183fd811cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FriendList(friends=[FriendInfo(name='Ollama', age=22, is_available=False), FriendInfo(name='Alonso', age=23, is_available=True)])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "friends_response.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18aa7d1f-6659-4e90-be97-de1ccb112786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': '{\\n  \"friends\": [\\n    {\\n      \"name\": \"Ollama\",\\n      \"age\": 22,\\n      \"is_available\": false\\n    },\\n    {\\n      \"name\": \"Alonso\",\\n      \"age\": 23,\\n      \"is_available\": true\\n    }\\n  ]\\n}',\n",
       " 'refusal': None,\n",
       " 'role': 'assistant',\n",
       " 'annotations': None,\n",
       " 'audio': None,\n",
       " 'function_call': None,\n",
       " 'tool_calls': None,\n",
       " 'parsed': {'friends': [{'name': 'Ollama', 'age': 22, 'is_available': False},\n",
       "   {'name': 'Alonso', 'age': 23, 'is_available': True}]},\n",
       " 'reasoning': 'Okay, the user wants a list of their two friends in JSON format. Let me start by understanding the details they provided.\\n\\nFirst friend is Ollama, 22 years old, and busy saving the world. Second is Alonso, 23, wants to hang out. Need to structure this into a JSON array with objects for each friend.\\n\\nEach object should have name, age, and a description. For Ollama, the description is \"busy saving the world\". Alonso\\'s is \"wants to hang out\". \\n\\nCheck if the JSON syntax is correct: keys in quotes, commas between objects, proper brackets. Also, ensure the age is a number, not a string. Let me put that together.\\n'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "friends_response.model_dump()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
